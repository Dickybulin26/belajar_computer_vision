{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV - Part 5\n",
    "\n",
    "- Region Mask\n",
    "- Range Thresholding\n",
    "- Shape Detection (Hough Transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region Mask\n",
    "\n",
    "- Highly useful while extracting any part of the image, defining and working with **non-rectangular ROI** (region of interest). <br>\n",
    "  <img src=\"resource/sample_mask.png\" style=\"width:500px; margin-top:10px\"></img>\n",
    "- Region Mask on image is user **Bitwise Operation** (AND, OR, NOT, and XOR operation).\n",
    "<img src=\"resource/bitwise_operator.jpg\" style=\"width:500px; margin-top:10px\"></img>\n",
    "- Method :\n",
    "    - `cv2.bitwise_not(img1, mask)`\n",
    "    - `cv2.bitwise_and(img1, img2, mask)`\n",
    "    - `cv2.bitwise_or(img1, img2, mask)`\n",
    "    - `cv2.bitwise_xor(img1, img2, mask)`\n",
    "- with parameter :\n",
    "    - `img1` : input image 1\n",
    "    - `img2` : input image 2\n",
    "    - `mask` : optional operation mask, **8-bit single channel** array, that specifies **elements of the output array to be changed**. <br>\n",
    "    <img src=\"resource/mask_hand.png\" style=\"width:200px; margin-top:10px\"></img>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bitwise Not\n",
    "- Bitwise not dalam python menggunakan operator `~`\n",
    "- Misal pixel value $200_{10} = 11001000_2$, \n",
    "- Jika diterapkan bitwise not pada pixel tersebut, maka akn dihasilkan nilai pixel baru $00110111_2=55_{10}$\n",
    "\n",
    "```\n",
    "11001000\n",
    "-------- ~\n",
    "00110111\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([200]).astype(np.uint8)\n",
    "print (~a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55]], dtype=uint8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.bitwise_not(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bitwise not untuk mask lingkaran putih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"lena.jpg\")\n",
    "h, w, c = img.shape\n",
    "\n",
    "mask = np.zeros((h, w)).astype(np.uint8)\n",
    "cv2.circle(mask, (h//2, w//2), 100, (255, 255,  255), -1)\n",
    "\n",
    "mask_inv = cv2.bitwise_not(img, mask=mask)\n",
    "\n",
    "cv2.imshow('original', img)\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('mask_inv', mask_inv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bitwise Not untuk mask hasil thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"hand.png\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV)\n",
    "mask_inv = cv2.bitwise_not(img, mask=thresh)\n",
    "\n",
    "cv2.imshow('Bitwise Or', mask_inv)\n",
    "cv2.imshow('Mask', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Menambahkan trackbar untuk memvariasikan nilai threshold sebelum di apply Bitwise Not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = 255\n",
    "default_value = 120\n",
    "\n",
    "title_window = 'Bitwise Not'\n",
    "\n",
    "def on_trackbar(val):\n",
    "    ret, thresh = cv2.threshold(gray, val, 255, cv2.THRESH_BINARY_INV)\n",
    "    mask_inv = cv2.bitwise_not(img, mask=thresh)\n",
    "    cv2.imshow(title_window, mask_inv)\n",
    "\n",
    "img = cv2.imread(\"hand.png\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.namedWindow(title_window)\n",
    "cv2.createTrackbar('thresh', title_window , default_value, max_value, on_trackbar)\n",
    "\n",
    "on_trackbar(default_value)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitwise And\n",
    "\n",
    "- Bitwise And dalam python menggunakan operator `&`\n",
    "- Misal pixel value 1 = $100_{10} = 01100100_2$, \n",
    "- dan pixel value 2 = $40_{10} = 00101000_2$, \n",
    "- Jika diterapkan bitwise And pada pixel tersebut, maka akan dihasilkan nilai pixel baru $00100000_2=32_{10}$\n",
    "\n",
    "```\n",
    "01100100\n",
    "00101000\n",
    "-------- &\n",
    "00100000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100], dtype=uint8)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([100]).astype(np.uint8)\n",
    "b = np.array([100]).astype(np.uint8)\n",
    "\n",
    "a & b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32]], dtype=uint8)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.bitwise_and(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bitwise And untuk mask kotak putih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"lena.jpg\")\n",
    "img2 = cv2.imread(\"apple.jpg\")\n",
    "h, w, c = img1.shape\n",
    "\n",
    "mask = np.zeros((h, w)).astype(np.uint8)\n",
    "cv2.rectangle(mask, (h//4, w//4), (3*h//4, 3*w//4), (255, 255,  255), -1)\n",
    "\n",
    "mask_and = cv2.bitwise_and(img2, img2, mask=mask)\n",
    "\n",
    "cv2.imshow('mask_inv', mask_and)\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bitwise And untuk mask hasil thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"apple.jpg\")\n",
    "gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "img2 = cv2.imread(\"lena.jpg\")\n",
    "mask_inv = cv2.bitwise_and(img1, img2, mask=thresh)\n",
    "\n",
    "cv2.imshow('Bitwise Or', mask_inv)\n",
    "cv2.imshow('Apple mask', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitwise Or\n",
    "\n",
    "- Bitwise Or dalam python menggunakan operator `&`\n",
    "- Misal pixel value 1 = $100_{10} = 01100100_2$, \n",
    "- dan pixel value 2 = $40_{10} = 00101000_2$, \n",
    "- Jika diterapkan bitwise And pada pixel tersebut, maka akan dihasilkan nilai pixel baru $01101100_2=108_{10}$\n",
    "\n",
    "```\n",
    "01100100\n",
    "00101000\n",
    "-------- |\n",
    "01101100\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([108], dtype=uint8)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([100]).astype(np.uint8)\n",
    "b = np.array([40]).astype(np.uint8)\n",
    "\n",
    "a | b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[108]], dtype=uint8)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.bitwise_or(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bitwise Or untuk mask lingkaran putih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"lena.jpg\")\n",
    "img2 = cv2.imread(\"apple.jpg\")\n",
    "h, w, c = img1.shape\n",
    "\n",
    "mask = np.zeros((h, w)).astype(np.uint8)\n",
    "cv2.circle(mask, (h//2, w//2), 100, (255, 255,  255), -1)\n",
    "\n",
    "mask_and = cv2.bitwise_or(img1, img2, mask=mask)\n",
    "\n",
    "cv2.imshow('mask_inv', mask_and)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bitwise Or untuk mask hasil thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"apple.jpg\")\n",
    "gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "img2 = cv2.imread(\"lena.jpg\")\n",
    "mask_inv = cv2.bitwise_or(img2, img2, mask=thresh)\n",
    "\n",
    "cv2.imshow('Bitwise Or', mask_inv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range Thresholding\n",
    "\n",
    "- Image thresholding using `cv2.threshold()` function. <br>\n",
    "<img src=\"resource/Binary_Thresh.png\" style=\"width: 500px; margin-top:10px;\" > </img>\n",
    "- Now we will learn how to do **range based thresholding** using  `cv2.inRange()` function. <br>\n",
    "<img src=\"resource/Range_Thresh.png\" style=\"width: 500px; margin-top:10px;\" > </img>\n",
    "- The concept remains the same, but now we add a range of pixel values we need.\n",
    "- Method `cv2.inRange(img, lower_color, upper_color)`\n",
    "- where theparameter :\n",
    "    - `img` : input image (HSV color space)\n",
    "    - `lower_color` : tuple (H, S, V) of lower color \n",
    "    - `upper_color` : tuple (H, S, V) of upper color \n",
    "- `H, S, V` value range in OpenCV:\n",
    "    - `H` (0 - 180)\n",
    "    - `S` (0 - 255)\n",
    "    - `V` (0 - 255)\n",
    "- `cv2.inRange()` using **HSV colorspace**, since the **hue channel** models the **color type**, it is very useful in image processing tasks that need to **segment objects based on its color**.<br>\n",
    "<img src=\"resource/Threshold_inRange_HSV_colorspace.jpg\" style=\"width: 300px; margin-top:10px;\" > </img>\n",
    "- Since colors in the **RGB colorspace** are coded using the **three channels**, it is **more difficult** to segment an object in the image based on its color.<br>\n",
    "<img src=\"resource/Threshold_inRange_RGB_colorspace.jpg\" style=\"width: 300px; margin-top:10px;\" > </img>\n",
    "- **HSV colorspace** model : <br>\n",
    "<img src=\"resource/HSV_hue_model.png\" style=\"width: 300px; margin-top:10px;\" > </img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conver RGB value to HSV (`cv2.cvtColor()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[120 255 255]]]\n"
     ]
    }
   ],
   "source": [
    "green = np.uint8([[[255,0,0 ]]])\n",
    "hsv_green = cv2.cvtColor(green, cv2.COLOR_BGR2HSV)\n",
    "print( hsv_green )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Detect Red, Green and Blue Color from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('blocks.jpg')\n",
    "\n",
    "#convert to hsv\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# define range of blue color in HSV\n",
    "lower_blue = np.array([110, 50, 50])\n",
    "upper_blue = np.array([130, 255, 255])\n",
    "\n",
    "# define range of red color in HSV\n",
    "lower_red = np.array([-10, 50, 50])\n",
    "upper_red = np.array([10, 255, 255])\n",
    "\n",
    "# define range of green color in HSV\n",
    "lower_green = np.array([50, 50, 50])\n",
    "upper_green = np.array([70, 255, 255])\n",
    "\n",
    "# Threshold the HSV image to get only blue colors\n",
    "mask_blue = cv2.inRange(hsv.copy(), lower_blue, upper_blue)\n",
    "mask_red = cv2.inRange(hsv.copy(), lower_red, upper_red)\n",
    "mask_green = cv2.inRange(hsv.copy(), lower_green, upper_green)\n",
    "\n",
    "mask = mask_blue + mask_red + mask_green\n",
    "\n",
    "res = cv2.bitwise_and(img, img, mask= mask)\n",
    "\n",
    "cv2.imshow('frame',img)\n",
    "cv2.imshow('res',res)\n",
    "cv2.imshow('mask',mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "- Input video Detect color yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- jawaban ----\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define range of yellow color in HSV\n",
    "lower_yellow = np.array([25, 50, 50])\n",
    "upper_yellow = np.array([35, 255, 255])\n",
    "\n",
    "cap = cv2.VideoCapture(\"yellow_ball.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret :\n",
    "        frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv.copy(), lower_yellow, upper_yellow)\n",
    "        res = cv2.bitwise_and(frame, frame, mask= mask)\n",
    "        \n",
    "        cv2.imshow('Detected Object',res)\n",
    "\n",
    "        if cv2.waitKey(10) == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape Detection\n",
    "\n",
    "### Hough Line Transform (Line Detector)\n",
    "\n",
    "<img src=\"resource/lane.gif\" style=\"width:500px, margin-top:10px\"></img>\n",
    "- The Hough Line Transform is a transform used to detect **straight lines**.\n",
    "- To apply the Transform, first an **edge detection** pre-processing is desirable.\n",
    "- As you know, a line in the image space can be expressed with two variables. For example:\n",
    "    - In the **Cartesian** coordinate system: Parameters: ($m$,$b$).\n",
    "    - In the **Polar** coordinate system: Parameters: ($r$,$θ$). <br>\n",
    "      <img src=\"resource/Hough_Lines_Tutorial_Theory_0.jpg\" style=\"width:400px, margin-top:10px\"></img>\n",
    "    - For Hough Transforms, we will express lines in the *Polar system*. Hence, a line equation can be written as: <br>\n",
    "    $y = \\left ( -\\dfrac{\\cos \\theta}{\\sin \\theta} \\right ) x + \\left ( \\dfrac{r}{\\sin \\theta} \\right )$ <br>\n",
    "    Arranging the terms: $r = x \\cos \\theta + y \\sin \\theta$ <br>\n",
    "    - In general for each point ($x_{0}, y_{0}$), we can define the family of lines that goes through that point as: <br>\n",
    "        $r_{\\theta} = x_{0} \\cdot \\cos \\theta + y_{0} \\cdot \\sin \\theta$ <br>\n",
    "        Meaning that each pair ($r_{\\theta},\\theta$) represents each line that passes by ($x_{0}, y_{0}$).\n",
    "    - If for a given ($x_{0}, y_{0}$) we plot the family of lines that goes through it, we get a sinusoid. For instance, for $x_{0}$=8 and $y_{0}$=6 we get the following plot (in a plane $θ - r$): <br>\n",
    "        <img src=\"resource/Hough_Lines_Tutorial_Theory_1.jpg\" style=\"width:400px, margin-top:10px\"></img> <br>\n",
    "        We consider only points such that $r > 0$ and $0< \\theta < 2 \\pi$.\n",
    "    - We can do the same operation above for all the points in an image. If the curves of two different points intersect in the plane $θ - r$, that means that both points belong to a same line. For instance, following with the example above and drawing the plot for two more points: $x_{1}=4, y_{1}=9$ and $x_{2}=12, y_{2}=3$, we get: <br>\n",
    "        <img src=\"resource/Hough_Lines_Tutorial_Theory_2.jpg\" style=\"width:400px, margin-top:10px\"></img> <br>\n",
    "        The three plots intersect in one single point (0.925,9.6), these coordinates are the parameters (θ$,r$) or the line in which ($x_{0},y_{0}$), ($x_{1},y_{1}$) and ($x_{2},y_{2}$) lay.\n",
    "    > A line can be detected by finding the **number of intersections between curves**.The **more curves intersecting** means that the line represented by that **intersection have more points**.\n",
    "    > In general, we can define a **threshold** of the **minimum number of intersections** needed to **detect a line**.\n",
    "    > This is what the **Hough Line Transform** does. It keeps track of the intersection between curves of every point in the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenCV implements two kind of Hough Line Transforms:\n",
    "\n",
    "- The **Standard Hough Transform** <br>\n",
    "    It consists in pretty much what we just explained in the previous section. It gives you as result a vector of couples ($θ,rθ$)\n",
    "    In OpenCV it is implemented with the function `cv2.HoughLines()`.\n",
    "\n",
    "- The **Probabilistic Hough Line Transform** <br>\n",
    "    A more efficient implementation of the Hough Line Transform. It gives as output the extremes of the detected lines ($x_{0},y_{0},x_{1},y_{1}$)\n",
    "    In OpenCV it is implemented with the function `cv2.HoughLinesP()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Hough Transform `cv2.HoughLines()`\n",
    "\n",
    "- menggunakan method `cv2.HoughLines(img, rho, theta, threshold, lines, srn, stn)`\n",
    "- with the following arguments:\n",
    "    - `img` : input image (edge image)\n",
    "    - `rho` : The resolution of the parameter r in pixels. We use 1 pixel.\n",
    "    - `theta` : The resolution of the parameter θ in radians. We use 1 degree (`np.pi/180`)\n",
    "    - `threshold` : The minimum number of intersections to *detect* a line\n",
    "    - `lines` : A vector that will store the parameters ($r,θ$) of the detected lines\n",
    "    - `srn` and `stn` : Default parameters to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('road.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 200)\n",
    "\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, 100, None, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    rho = line[0][0]\n",
    "    theta = line[0][1]\n",
    "    a = math.cos(theta)\n",
    "    b = math.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    x1, y1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
    "    x2, y2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow(\"Hough Line Transform\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trackbar mengatur nilai threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = 300\n",
    "default_value = 150\n",
    "\n",
    "title_window = \"Hough Line Transform\"\n",
    "\n",
    "def on_trackbar(val):\n",
    "    frame = img.copy()\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, val, None, 0, 0)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho = line[0][0]\n",
    "            theta = line[0][1]\n",
    "            a = math.cos(theta)\n",
    "            b = math.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1, y1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
    "            x2, y2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(title_window, frame)\n",
    "\n",
    "img = cv2.imread('road.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 200)\n",
    "\n",
    "cv2.namedWindow(title_window)\n",
    "cv2.createTrackbar('thresh', title_window , default_value, max_value, on_trackbar)\n",
    "\n",
    "on_trackbar(default_value)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilistic  Hough Transform `cv2.HoughLinesP()`\n",
    "\n",
    "- menggunakan method `cv2.HoughLinesP(img, rho, theta, threshold, lines, minLinLength, maxLineGap)`\n",
    "- with the following arguments:\n",
    "    - `img` : input image (edge image)\n",
    "    - `rho` : The resolution of the parameter r in pixels. We use 1 pixel.\n",
    "    - `theta` : The resolution of the parameter θ in radians. We use 1 degree (`np.pi/180`)\n",
    "    - `threshold` : The minimum number of intersections to *detect* a line\n",
    "    - `lines` : A vector that will store the parameters ($r,θ$) of the detected lines\n",
    "    - `minLinLength` : The minimum number of points that can form a line. Lines with less than this number of points are disregarded.\n",
    "    - `maxLineGap` : The maximum gap between two points to be considered in the same line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('road.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 200)\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, minLineLength=50, maxLineGap=30)\n",
    "\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Result Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trackbar untuk mengatur `minLinLength` dan `maxLineGap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLineGap = 20\n",
    "minLineLength = 100\n",
    "\n",
    "title_window = \"Hough Line Transform\"\n",
    "\n",
    "def draw_line(lines):\n",
    "    frame = img.copy()\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(title_window, frame)  \n",
    "    \n",
    "def on_trackbar_minLineLength(val):\n",
    "    global minLineLength\n",
    "    minLineLength = val\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, minLineLength=minLineLength, maxLineGap=maxLineGap)\n",
    "    draw_line(lines)\n",
    "    \n",
    "def on_trackbar_maxLineGap(val):\n",
    "    global maxLineGap\n",
    "    maxLineGap = val\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, minLineLength=minLineLength, maxLineGap=maxLineGap)\n",
    "    draw_line(lines)\n",
    "\n",
    "img = cv2.imread('road.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 200)\n",
    "\n",
    "cv2.namedWindow(title_window)\n",
    "cv2.createTrackbar('maxGap', title_window , 20, 200, on_trackbar_maxLineGap)\n",
    "cv2.createTrackbar('minLen', title_window , 100, 200, on_trackbar_minLineLength)\n",
    "\n",
    "on_trackbar_minLineLength(100)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hough Circle Transform\n",
    "- The Hough Circle Transform works in a roughly analogous way to the Hough Line Transform explained in the previous tutorial.\n",
    "- In the line detection case, a line was defined by two parameters ($r,θ$). \n",
    "- Parameters to define a circle:\n",
    "$C : ( x_{center}, y_{center}, r )$\n",
    "- where ($x_{center},y_{center}$) define the center position (green point) and $r$ is the radius, which allows us to completely define a circle, as it can be seen below:\n",
    " <img src=\"resource/Hough_Circle_Tutorial_Theory_0.jpg\" style=\"width:400px, margin-top:10px\"></img>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hough Circle Transform `cv2.HoughCircles()`\n",
    "\n",
    "- menggunakan method `cv2.HoughCircles(img, mode, dp, min_dist_center, param1, param2, min_radius, max_radius)`\n",
    "- with the arguments:\n",
    "    - `img` : input image.\n",
    "    - `mode` : \n",
    "        - `cv2.HOUGH_STANDARD` : Classical or standard Hough transform.\n",
    "        - `cv2.HOUGH_PROBABILISTIC` : Probabilistic Hough transform (more efficient in case if the picture contains a few long linear segments).\n",
    "        - `cv2.HOUGH_MULTI_SCALE` : multi-scale variant of the classical Hough transform. \n",
    "        - `cv2.HOUGH_GRADIENT`\n",
    "    - `dp` : The inverse ratio of resolution (default 1).\n",
    "    - `min_dist_center` : Minimum distance between detected centers.\n",
    "    - `param1` : Upper threshold for the internal Canny edge detector.\n",
    "    - `param2` : Threshold for center detection.\n",
    "    - `min_radius` : Minimum radius to be detected. If unknown, put zero as default.\n",
    "    - `max_radius` : Maximum radius to be detected. If unknown, put zero as default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('eye.jpg')\n",
    "h, w, c = img.shape\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.GaussianBlur(gray,(5,5), 0, 0)\n",
    "\n",
    "circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1, h/64, param1=200, param2=17, minRadius=21, maxRadius=30)\n",
    "\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))[0]\n",
    "    for i in circles:\n",
    "        cv2.circle(img, (i[0], i[1]), i[2], (0, 255, 0), 2)\n",
    "\n",
    "        \n",
    "cv2.imshow(\"output\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "minRadius = 21\n",
    "maxRadius = 30\n",
    "param1 = 200\n",
    "param2 = 17\n",
    "\n",
    "title_window = \"Hough Circle Transform\"\n",
    "\n",
    "def draw_circle(circles):\n",
    "    frame = img.copy()\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))[0]\n",
    "        for i in circles:\n",
    "            cv2.circle(frame, (i[0], i[1]), i[2], (0, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(title_window, frame)  \n",
    "    \n",
    "def on_trackbar_minRadius(val):\n",
    "    global minRadius\n",
    "    minRadius = val\n",
    "    circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1, h/64, param1=param1, param2=param2, minRadius=minRadius, maxRadius=maxRadius)\n",
    "    draw_circle(circles)\n",
    "    \n",
    "def on_trackbar_maxRadius(val):\n",
    "    global maxRadius\n",
    "    maxRadius = val\n",
    "    circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1, h/64, param1=param1, param2=param2, minRadius=minRadius, maxRadius=maxRadius)\n",
    "    draw_circle(circles)\n",
    "    \n",
    "def on_trackbar_param1(val):\n",
    "    global param1\n",
    "    param1 = val\n",
    "    circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1, h/64, param1=param1, param2=param2, minRadius=minRadius, maxRadius=maxRadius)\n",
    "    draw_circle(circles)\n",
    "    \n",
    "def on_trackbar_param2(val):\n",
    "    global param2\n",
    "    param2 = val\n",
    "    circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1, h/64, param1=param1, param2=param2, minRadius=minRadius, maxRadius=maxRadius)\n",
    "    draw_circle(circles)\n",
    "\n",
    "img = cv2.imread('eye.jpg')\n",
    "h, w, c = img.shape\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray,(5,5), 0, 0)\n",
    "\n",
    "cv2.namedWindow(title_window)\n",
    "cv2.createTrackbar('minRadius', title_window , 21, 50, on_trackbar_minRadius)\n",
    "cv2.createTrackbar('maxRadius', title_window , 30, 50, on_trackbar_maxRadius)\n",
    "cv2.createTrackbar('param1', title_window , 200, 255, on_trackbar_param1)\n",
    "cv2.createTrackbar('param2', title_window , 17, 30, on_trackbar_param2)\n",
    "\n",
    "on_trackbar_minRadius(minRadius)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "- Dectect Yellow Ball on video `yellow_bal.mp4` using Hough Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- jawaban ----\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"yellow_ball.mp4\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret :\n",
    "        frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, h/2, param1=180, param2=17, minRadius=21, maxRadius=100)\n",
    "\n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))[0]\n",
    "            for i in circles:\n",
    "                cv2.circle(frame, (i[0], i[1]), i[2], (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow('Hough Circle - Video', frame)\n",
    "\n",
    "        if cv2.waitKey(10) == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplication Hough Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Real-tim Road Line Detection <br>\n",
    "Original Video : [https://www.youtube.com/watch?v=KWJaBJYJIjI](https://www.youtube.com/watch?v=KWJaBJYJIjI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLineGap = 200\n",
    "minLineLength = 50\n",
    "title_window = \"Road Lane Detector\"\n",
    "poly = [[59, 339], [293, 217], [434, 210], [613, 325]]\n",
    "is_draw = False\n",
    "\n",
    "def on_trackbar_minLineLength(val):\n",
    "    global minLineLength\n",
    "    minLineLength = val\n",
    "\n",
    "def on_trackbar_maxLineGap(val):\n",
    "    global maxLineGap\n",
    "    maxLineGap = val\n",
    "    \n",
    "def read_poly(event,x,y,flags,param):\n",
    "    global poly, is_draw\n",
    "    \n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        is_draw = True\n",
    "        poly = []\n",
    "        \n",
    "    if event == cv2.EVENT_LBUTTONDOWN and is_draw:\n",
    "        poly.append([x, y])\n",
    "    \n",
    "    if len(poly) == 4 and is_draw:\n",
    "        is_draw = False\n",
    "    \n",
    "cv2.namedWindow(title_window)\n",
    "cv2.createTrackbar('maxGap', title_window , 200, 400, on_trackbar_maxLineGap)\n",
    "cv2.createTrackbar('minLen', title_window , 50, 400, on_trackbar_minLineLength)\n",
    "cv2.setMouseCallback(title_window, read_poly) \n",
    "\n",
    "cap = cv2.VideoCapture('drive.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret :\n",
    "        frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if not is_draw :\n",
    "            stencil = np.zeros_like(gray)\n",
    "            polygon = np.array(poly)\n",
    "            cv2.fillConvexPoly(stencil, polygon, 1)\n",
    "            roi = cv2.bitwise_and(gray, gray, mask=stencil)\n",
    "\n",
    "            ret, thresh = cv2.threshold(roi, 130, 255, cv2.THRESH_BINARY)\n",
    "            cv2.imshow('roi', roi)\n",
    "\n",
    "            lines = cv2.HoughLinesP(thresh, rho=1, theta=np.pi/180, threshold=20, minLineLength=minLineLength, maxLineGap=maxLineGap)\n",
    "            if lines is not None:\n",
    "                for line in lines:\n",
    "                    x1, y1, x2, y2 = line[0]\n",
    "                    cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(title_window, frame)\n",
    "\n",
    "        if cv2.waitKey(25) == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Real-time Lane Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dari hasil sebelumnya kita dapat mendeteksi Road Lane dengan menggunakan `cv2.HoughLinesP()`\n",
    "- Namun banyak `lines` yang terdeteksi disisi kanan maupun  kiri,\n",
    "<img src=\"resource/overlay_v1.png\" style=\"width: 500px; margin-top:10px;\" > </img> <br>\n",
    "<img src=\"resource/slope_intersect.png\" style=\"width: 400px; margin-top:10px;\" > </img> <br>\n",
    "- Rata-ratakan slope ($m$) dan Intersept ($c$), disisi kanan dan kiri,<br>\n",
    "<img src=\"resource/slope_intersect_mean.png\" style=\"width: 400px; margin-top:10px;\" > </img>\n",
    "- Setelahnya tentukan ($x_1, y_1$) dan ($x_2, y_2$) sisi kanan dan kiri,<br>\n",
    "<img src=\"resource/coordinate.png\" style=\"width: 500px; margin-top:10px;\" > </img>\n",
    "- Tambahkan overlay sebagai berikut dari `lines` yang didapatkan  `cv2.HoughLinesP()` <br>\n",
    "<img src=\"resource/overlay.png\" style=\"width: 500px; margin-top:10px;\" > </img> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_window = \"Road Lane Detector\"\n",
    "roi_poly = np.array([[59, 339], [293, 217], [434, 210], [613, 325]])\n",
    "\n",
    "cap = cv2.VideoCapture('drive.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret : \n",
    "        frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        mask = np.zeros(gray.shape).astype(np.uint8)\n",
    "        cv2.fillPoly(mask, [roi_poly], (255,255,255))\n",
    "        roi = cv2.bitwise_and(gray, gray, mask=mask)\n",
    "\n",
    "        ret, thresh = cv2.threshold(roi, 130, 255, cv2.THRESH_BINARY)\n",
    "        edged = cv2.Canny(thresh, 127, 200)\n",
    "\n",
    "        lines = cv2.HoughLinesP(edged, 1, np.pi/180, 10, np.array([]), minLineLength=20, maxLineGap=5)\n",
    "\n",
    "        overlay = draw_lines(edged.shape, lines, thickness=3, scale = 0.65)\n",
    "        frame = cv2.addWeighted(overlay, 1, frame, 0.8, 0)\n",
    "\n",
    "        cv2.imshow(title_window, frame)\n",
    "        cv2.imshow(title_window + \"- ROI\", roi)\n",
    "        cv2.imshow(title_window + \"- Edge\", edged)\n",
    "        cv2.imshow(title_window + \"- thresh\", thresh)\n",
    "        if cv2.waitKey(25) == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_m, l_m, r_c, l_c = [],[],[],[]\n",
    "def draw_lines(shape, lines, thickness=3, scale = 0.65):\n",
    "    global r_m, l_m, r_c, l_c\n",
    "    h, w = shape\n",
    "    img = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    \n",
    "    if lines is not None :\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                slope = (y1-y2)/(x1-x2)\n",
    "                if slope > 0.3:\n",
    "                    yintercept = y2 - (slope*x2)\n",
    "                    r_m.append(slope)\n",
    "                    r_c.append(yintercept)\n",
    "                elif slope < -0.3:\n",
    "                    yintercept = y2 - (slope*x2)\n",
    "                    l_m.append(slope)\n",
    "                    l_c.append(yintercept)\n",
    "\n",
    "    avg_l_m = np.mean(l_m[-30:])\n",
    "    avg_l_c = np.mean(l_c[-30:])\n",
    "    avg_r_m = np.mean(r_m[-30:])\n",
    "    avg_r_c = np.mean(r_c[-30:])\n",
    "\n",
    "    try:\n",
    "        y1, y2 = int(scale*h), h\n",
    "        l_x1 = int((y1 - avg_l_c)/avg_l_m)\n",
    "        l_x2 = int((y2 - avg_l_c)/avg_l_m)\n",
    "        r_x1 = int((y1- avg_r_c)/avg_r_m)\n",
    "        r_x2 = int((y2 - avg_r_c)/avg_r_m)\n",
    "        \n",
    "        pts = np.array([[l_x1, y1],[l_x2, y2],[r_x2, y2],[r_x1, y1]]).astype(np.int32)\n",
    "        pts = pts.reshape((-1,1,2))\n",
    "        cv2.fillPoly(img,[pts],(0,127,50))\n",
    "        cv2.line(img, (l_x1, y1), (l_x2, y2), (0,255,255), thickness)\n",
    "        cv2.line(img, (r_x1, y1), (r_x2, y2), (0,255,255), thickness)\n",
    "        return img\n",
    "    except ValueError:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv_env]",
   "language": "python",
   "name": "conda-env-opencv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
